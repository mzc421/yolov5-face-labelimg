# Face Labeling v0.2.2
# åˆ›å»ºäººï¼šæ›¾é€¸å¤«
# åˆ›å»ºæ—¶é—´ï¼š2022-07-20

import argparse
import gc
import os
import sys
import time
from collections import Counter
from datetime import datetime
from pathlib import Path

import cv2
import numpy as np
import torch
from rich.console import Console
from rich.table import Table

from tools.coco_json import coco_json_main
from tools.log import rich_log
from tools.obj_opt import get_obj_size
from tools.time_format import time_format
from tools.voc_xml import create_xml
from tools.yolo_txt import create_yolo_txt

from models.common import DetectMultiBackend
from utils.torch_utils import select_device, smart_inference_mode
from utils.augmentations import letterbox
from utils.general import non_max_suppression, Profile, increment_path, scale_boxes

# ---------------------å›¾ç‰‡å’Œè§†é¢‘è¾“å…¥æ ¼å¼---------------------
IMG_FORMATS = ["jpg", "jpeg", "png", "bmp", "tif", "webp"]
VIDEO_FORMATS = ["mp4", "avi", "wmv", "mkv", "mov", "gif", "vob", "swf", "mpg", "flv", "3gp", "3g2"]

ROOT_PATH = sys.path[0]  # æ ¹ç›®å½•
FACELABELING_VERISON = "Face Labeling v1.0"

coco_imgs_list = []  # å›¾ç‰‡åˆ—è¡¨ï¼ˆCOCOï¼‰
coco_anno_list = []  # æ ‡æ³¨åˆ—è¡¨ï¼ˆCOCOï¼‰
categories_id = 0  # ç±»åˆ«IDï¼ˆCOCOï¼‰

color_list = [(0, 0, 255), (0, 255, 0), (181, 228, 255)]

console = Console()


def parse_args(known=False):
    parser = argparse.ArgumentParser(description="Face Labeling v0.2.2")
    parser.add_argument("--device", default="0", type=str, help="cuda or cpu")
    parser.add_argument("--mode", default="video", type=str, choices=['video', 'img', 'webcam'], help="face labeling mode")
    parser.add_argument("--img_dir",
                        default=r"D:\BaiduNetdiskDownload\face-labeling-master\face-labeling-master\data\imgs",
                        type=str, help="image dir")
    parser.add_argument("--video_dir",
                        default=r"D:\BaiduNetdiskDownload\face-labeling-master\face-labeling-master\data\videos",
                        type=str, help="video dir")
    parser.add_argument("--model_name", default="widerface-m.pt", type=str, help="model name")
    parser.add_argument("--imgName", default="face_test", type=str, help="image name")
    parser.add_argument("--project", default="runs", type=str, help="frame save dir")
    parser.add_argument("--exp", default="exp", type=str, help="frame dir name")
    parser.add_argument("--nms_conf", default=0.45, type=float, help="model NMS confidence threshold")
    parser.add_argument("--nms_iou", default=0.25, type=float, help="model NMS IoU threshold")
    parser.add_argument("--max_det", default=1000, type=int, help="model max detect obj num")
    parser.add_argument("--img_size", default=640, type=int, help="model inference size")
    parser.add_argument("--label_no_show", action="store_true", default=False, help="label show")
    parser.add_argument("--label_simple", default="dnt", type=str, choices=["dnt", "id", "conf"], help="label simple, dnt or id or conf")
    parser.add_argument("--label_progressBar", default="bar", type=str, choices=["bar", "dnt", "bar"], help="label progress bar, dnt or bar")
    args = parser.parse_known_args()[0] if known else parser.parse_args()
    return args


# äººè„¸æ£€æµ‹ä¸ä¿¡æ¯æå–
def face_detect(file_path, mode, frame, model, frame_id, face_id, stride, names, auto, max_det, frame_savePath, conf_thres,
                iou_thres, imgName, img_size=640, label_no_show=False, label_simple="dnt",
                label_progressBar="dnt", video_name="vide_name.mp4"):
    global coco_imgs_list, coco_anno_list, categories_id

    wait_key = cv2.waitKey(20) & 0xFF  # é”®ç›˜ç›‘å¬
    xyxy_list = []  # xyxy åˆ—è¡¨ç½®ç©º
    obj_size_style_list = []  # ç›®æ ‡å°ºå¯¸ç±»å‹
    clsName_list = []  # ç±»åˆ«åˆ—è¡¨

    img_shape = frame.shape  # å¸§å°ºå¯¸
    frame_cp = frame.copy()  # åŸå§‹å›¾ç‰‡å‰¯æœ¬
    im = letterbox(frame, img_size, stride=stride, auto=auto)[0]  # padded resize
    im = im.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB
    im = np.ascontiguousarray(im)  # contiguous
    im = torch.from_numpy(im).to(model.device)
    im = im.half() if model.fp16 else im.float()  # uint8 to fp16/32
    im /= 255  # 0 - 255 to 0.0 - 1.0
    if len(im.shape) == 3:
        im = im[None]  # expand for batch dim

    dt = Profile(device=model.device)
    with dt:
        pred = model(im)

    pred = non_max_suppression(pred, conf_thres, iou_thres, max_det=max_det)

    # æ˜¾ç¤ºå¸§ID
    cv2.putText(frame, f"Frame ID: {frame_id}", (0, 40), cv2.FONT_HERSHEY_COMPLEX, 0.6, (0, 255, 0), 1)

    color_draw = color_list[1]

    for id, det in enumerate(pred):
        fps = f"{(1000 * float(dt.t)):.2f}"  # FPS
        if len(det):
            det[:, :4] = scale_boxes(im.shape[2:], det[:, :4], frame.shape).round()

            for *xyxy, conf, cls in reversed(det):
                c = int(cls)  # ç±»åˆ«ç´¢å¼•
                label = names[c]
                clsName_list.append([c, label])

                x0, y0, x1, y1 = [int(i.cpu().tolist()) for i in xyxy]
                xyxy_list.append([x0, y0, x1, y1])  # è¾¹æ¡†åæ ‡åˆ—è¡¨
                obj_size = get_obj_size([x0, y0, x1, y1])  # è·å–ç›®æ ‡å°ºå¯¸

                # --------æ ‡ç­¾å’Œè¾¹æ¡†é¢œè‰²è®¾ç½®--------
                if obj_size == "small":
                    color_draw = color_list[0]
                elif obj_size == "medium":
                    color_draw = color_list[1]
                elif obj_size == "large":
                    color_draw = color_list[2]

                obj_size_style_list.append(obj_size)  # è·å–ç›®æ ‡å°ºå¯¸åˆ—è¡¨

                conf = float(conf)  # ç½®ä¿¡åº¦

                if not label_no_show:
                    # --------æ ‡ç­¾æ ·å¼--------
                    if label_simple == "dnt":
                        label_style = f"{id}-{label}:{conf:.2f}"
                    elif label_simple == "id":
                        label_style = f"{id}"
                    elif label_simple == "conf":
                        label_style = f"{conf * 100:.0f}%"

                    # æ ‡ç­¾èƒŒæ™¯å°ºå¯¸
                    labelbg_size = cv2.getTextSize(label_style, cv2.FONT_HERSHEY_COMPLEX, 0.6, 1)

                    # æ ‡ç­¾èƒŒæ™¯
                    if label_progressBar == "dnt":
                        cv2.rectangle(frame, (x0, y0), (x0 + labelbg_size[0][0], y0 + labelbg_size[0][1]),
                                      color_draw, thickness=-1)
                    elif label_progressBar == "bar":
                        cv2.rectangle(frame, (x0, y0), (x0 + int((x1 - x0) * conf), y0 + labelbg_size[0][1]),
                                      color_draw, thickness=-1)

                # æ ‡ç­¾
                cv2.putText(frame, label_style, (x0, y0 + labelbg_size[0][1]), cv2.FONT_HERSHEY_COMPLEX,
                            0.6, (0, 0, 0), 1)

                # æ£€æµ‹æ¡†
                cv2.rectangle(frame, (x0, y0), (x1, y1), color_draw, 2)

            # å˜é‡å›æ”¶
            del id, c, label, x0, y0, x1, y1, conf

        # FPS
        cv2.putText(frame, f"FPS: {fps}", (0, 20), cv2.FONT_HERSHEY_COMPLEX,
                    0.6, (0, 255, 0), 1)

    print(f"{file_path} {pred[0].shape[0] if len(det) else 'no'} detections, {dt.t * 1E3:.1f}ms")

    # äººè„¸æ•°é‡
    cv2.putText(frame, f"Face Num: {len(xyxy_list)}", (0, 60), cv2.FONT_HERSHEY_COMPLEX,
                0.6, (0, 255, 0), 1)

    # ---------------------ç›®æ ‡å°ºå¯¸ç±»å‹---------------------
    small_num = Counter(obj_size_style_list)["small"]  # å°ç›®æ ‡
    medium_num = Counter(obj_size_style_list)["medium"]  # ä¸­ç›®æ ‡
    large_num = Counter(obj_size_style_list)["large"]  # å¤§ç›®æ ‡

    cv2.putText(frame, f"small: {small_num}", (0, 80), cv2.FONT_HERSHEY_COMPLEX, 0.6, (0, 255, 0), 1)
    cv2.putText(frame, f"medium: {medium_num}", (0, 100), cv2.FONT_HERSHEY_COMPLEX, 0.6, (0, 255, 0), 1)
    cv2.putText(frame, f"large: {large_num}", (0, 120), cv2.FONT_HERSHEY_COMPLEX, 0.6, (0, 255, 0), 1)

    imgName_faceid = f"{imgName}-{face_id}"  # å›¾ç‰‡åç§°-FaceID

    if mode == "webcam" and wait_key == ord("a"):
        # æ•è·è§†é¢‘å¸§
        cv2.imwrite(f"{frame_savePath}/org/{imgName_faceid}.jpg", frame_cp)  # ä¿å­˜åŸå§‹å›¾ç‰‡
        cv2.imwrite(f"{frame_savePath}/tag/{imgName_faceid}.jpg", frame)  # ä¿å­˜æ ‡è®°å›¾ç‰‡

        # åˆ›å»ºVOC XMLæ–‡ä»¶
        create_xml(f"{imgName_faceid}.jpg", f"{frame_savePath}/voc_xml/{imgName_faceid}.jpg",
                   img_shape, clsName_list, xyxy_list, obj_size_style_list,
                   f"{frame_savePath}/voc_xml/{imgName_faceid}.xml")

        create_yolo_txt(clsName_list, img_shape, xyxy_list, f"{frame_savePath}/yolo_txt/{imgName_faceid}.txt")

        # ------------åŠ å…¥cocoå›¾ç‰‡ä¿¡æ¯å’Œæ ‡æ³¨ä¿¡æ¯------------
        coco_imgs_list.append([face_id, f"{imgName_faceid}.jpg", img_shape[1], img_shape[0],
                               f"{datetime.now():%Y-%m-%d %H:%M:%S}", ])
        coco_anno_list.append(
            [[categories_id + i for i in range(len(xyxy_list))], face_id, clsName_list, xyxy_list])
        categories_id += len(xyxy_list)

        face_id += 1  # äººè„¸IDè‡ªå¢

    elif mode == "img":
        # æ•è·è§†é¢‘å¸§
        cv2.imwrite(f"{frame_savePath}/raw/{imgName_faceid}.jpg", frame_cp)  # ä¿å­˜åŸå§‹å›¾ç‰‡
        cv2.imwrite(f"{frame_savePath}/tag/{imgName_faceid}.jpg", frame)  # ä¿å­˜æ ‡è®°å›¾ç‰‡

        # åˆ›å»ºVOC XMLæ–‡ä»¶
        create_xml(f"{imgName_faceid}.jpg", f"{frame_savePath}/voc_xml/{imgName_faceid}.jpg",
                   img_shape, clsName_list, xyxy_list, obj_size_style_list,
                   f"{frame_savePath}/voc_xml/{imgName_faceid}.xml", )

        create_yolo_txt(clsName_list, img_shape, xyxy_list, f"{frame_savePath}/yolo_txt/{imgName_faceid}.txt")

        # ------------åŠ å…¥cocoå›¾ç‰‡ä¿¡æ¯å’Œæ ‡æ³¨ä¿¡æ¯------------
        coco_imgs_list.append([face_id,
                               f"{imgName_faceid}.jpg", img_shape[1], img_shape[0],
                               f"{datetime.now():%Y-%m-%d %H:%M:%S}", ])
        coco_anno_list.append([[categories_id + i for i in range(len(xyxy_list))],
                               face_id, clsName_list, xyxy_list])
        categories_id += len(xyxy_list)

        face_id += 1  # äººè„¸IDè‡ªå¢

    elif mode == "video":
        # æ•è·è§†é¢‘å¸§
        cv2.imwrite(f"{frame_savePath}/{video_name}/raw/{imgName_faceid}.jpg", frame_cp)  # ä¿å­˜åŸå§‹å›¾ç‰‡
        cv2.imwrite(f"{frame_savePath}/{video_name}/tag/{imgName_faceid}.jpg", frame)  # ä¿å­˜æ ‡è®°å›¾ç‰‡

        # åˆ›å»ºVOC XMLæ–‡ä»¶
        create_xml(f"{imgName_faceid}.jpg", f"{frame_savePath}/{video_name}/voc_xml/{imgName_faceid}.jpg",
                   img_shape, clsName_list, xyxy_list, obj_size_style_list,
                   f"{frame_savePath}/{video_name}/voc_xml/{imgName_faceid}.xml")

        create_yolo_txt(clsName_list, img_shape, xyxy_list,
                        f"{frame_savePath}/{video_name}/yolo_txt/{imgName_faceid}.txt")

        # ------------åŠ å…¥cocoå›¾ç‰‡ä¿¡æ¯å’Œæ ‡æ³¨ä¿¡æ¯------------
        coco_imgs_list.append([face_id, f"{imgName_faceid}.jpg", img_shape[1], img_shape[0],
                               f"{datetime.now():%Y-%m-%d %H:%M:%S}", ])
        coco_anno_list.append([[categories_id + i for i in range(len(xyxy_list))], face_id, clsName_list, xyxy_list])

        categories_id += len(xyxy_list)

        face_id += 1  # äººè„¸IDè‡ªå¢

    if mode == "webcam":
        return frame, wait_key, face_id
    elif mode == "img":
        return frame, face_id
    elif mode == "video":
        return frame, face_id


@smart_inference_mode()
def face_label(device="0", mode="webcam", img_dir="./data/imgs", video_dir="./data/videos", model_name="widerface-m",
               imgName="face_test", project="runs", exp="exp", nms_conf=0.25, nms_iou=0.45, max_det=1000, img_size=640,
               label_no_show=False, label_simple="dnt", label_progressBar="dnt"):
    device = select_device(device)
    model = DetectMultiBackend(f"{ROOT_PATH}/weights/{model_name}", device=device)
    stride, names, pt = model.stride, model.names, model.pt

    # ----------åˆ›å»ºå¸§æ–‡ä»¶----------
    frame_savePath = increment_path(Path(f"{ROOT_PATH}/{project}") / exp, exist_ok=False)  # å¢é‡è¿è¡Œ

    frame_savePath.mkdir(parents=True, exist_ok=True)  # åˆ›å»ºç›®å½•

    if mode in ["webcam", "img"]:
        # åˆ›å»ºåŸå§‹å›¾ç‰‡ç›®å½•
        Path(f"{frame_savePath}/raw").mkdir(parents=True, exist_ok=True)
        # åˆ›å»ºæ ‡è®°å›¾ç‰‡ç›®å½•
        Path(f"{frame_savePath}/tag").mkdir(parents=True, exist_ok=True)
        # åˆ›å»ºPASCAL VOC XMLç›®å½•
        Path(f"{frame_savePath}/voc_xml").mkdir(parents=True, exist_ok=True)
        # åˆ›å»ºMS COCO JSONç›®å½•
        Path(f"{frame_savePath}/coco_json").mkdir(parents=True, exist_ok=True)
        # åˆ›å»ºYOLO TXTç›®å½•
        Path(f"{frame_savePath}/yolo_txt").mkdir(parents=True, exist_ok=True)

    face_id = 0  # äººè„¸ID
    frame_id = 0  # å¸§ID

    logTime = f"{datetime.now():%Y-%m-%d %H:%M:%S}"  # æ—¥å¿—æ—¶é—´
    rich_log(f"{logTime}\n")  # è®°å½•æ—¥å¿—æ—¶é—´

    s_time = time.time()  # èµ·å§‹æ—¶é—´
    console.rule(f"ğŸ”¥ {FACELABELING_VERISON} ç¨‹åºå¼€å§‹ï¼")

    if mode == "webcam":
        cap = cv2.VideoCapture(0)  # è¿æ¥è®¾å¤‡
        is_capOpened = cap.isOpened()  # åˆ¤æ–­è®¾å¤‡æ˜¯å¦å¼€å¯
        count = 0
        frame_width = int(cap.get(3))  # å¸§å®½åº¦
        frame_height = int(cap.get(4))  # å¸§é«˜åº¦
        fps = cap.get(5)  # å¸§ç‡
        # è°ƒç”¨face webcam
        if is_capOpened:
            vid_writer = cv2.VideoWriter(f"{frame_savePath}//tag/webcam.mp4",
                                         cv2.VideoWriter_fourcc(*'mp4v'), fps,
                                         (frame_width, frame_height))

            print(f"ğŸš€ æ¬¢è¿ä½¿ç”¨{FACELABELING_VERISON}ï¼Œæ‘„åƒå¤´è¿æ¥æˆåŠŸï¼\n")  # æ‘„åƒå¤´è¿æ¥æˆåŠŸæç¤º
            while is_capOpened:
                _, frame = cap.read()  # å¸§è¯»å–
                cv2.namedWindow(FACELABELING_VERISON)  # è®¾ç½®çª—å£
                count += 1
                file_path = count
                # äººè„¸æ£€æµ‹ä¸ä¿¡æ¯æå–
                frame, wait_key, face_id = face_detect(file_path, mode, frame, model, frame_id, face_id, stride, names,
                                                       pt, max_det, frame_savePath, nms_conf, nms_iou,
                                                       imgName, img_size, label_no_show, label_simple,
                                                       label_progressBar)

                vid_writer.write(frame)
                cv2.imshow(FACELABELING_VERISON, frame)  # æ˜¾ç¤º

                if wait_key == ord("q"):
                    # é€€å‡ºçª—ä½“
                    break

                frame_id += 1  # å¸§IDè‡ªå¢

                # å˜é‡å›æ”¶
                del frame
                gc.collect()

            vid_writer.release()
            cap.release()
            coco_json_main(names, coco_imgs_list, coco_anno_list, f"{frame_savePath}/coco_json/face_coco.json")

        else:
            print("æ‘„åƒå¤´è¿æ¥å¼‚å¸¸ï¼")

    elif mode == "img":
        # ç­›é€‰å›¾ç‰‡æ–‡ä»¶
        imgName_list = [i for i in os.listdir(img_dir) if i.split(".")[-1].lower() in IMG_FORMATS]
        # è°ƒç”¨ face images
        for i in imgName_list:
            file_path = f"{img_dir}/{i}"
            frame = cv2.imread(file_path)

            frame, face_id = face_detect(file_path, mode, frame, model, frame_id, face_id, stride, names, pt, max_det,
                                         frame_savePath, nms_conf, nms_iou, imgName, img_size,
                                         label_no_show, label_simple, label_progressBar)

            frame_id += 1  # å¸§IDè‡ªå¢

            # å˜é‡å›æ”¶
            del frame
            gc.collect()

        coco_json_main(names, coco_imgs_list, coco_anno_list, f"{frame_savePath}/coco_json/face_coco.json")

    elif mode == "video":
        # ç­›é€‰å›¾ç‰‡æ–‡ä»¶
        videoName_list = [i for i in os.listdir(video_dir) if i.split(".")[-1].lower() in VIDEO_FORMATS]

        for i in videoName_list:
            video_path = os.path.join(video_dir, i)
            input_video = cv2.VideoCapture(video_path)
            is_capOpened = input_video.isOpened()

            frame_width = int(input_video.get(3))  # å¸§å®½åº¦
            frame_height = int(input_video.get(4))  # å¸§é«˜åº¦
            fps = input_video.get(5)  # å¸§ç‡
            video_frames = int(input_video.get(7))  # æ€»å¸§æ•°

            video_name = i.replace(".", "_")  # ç‚¹å·å–ä»£ä¸‹åˆ’çº¿

            print(f"{video_name}ï¼Œå¸§å®½åº¦ï¼š{frame_width}ï¼Œå¸§é«˜åº¦ï¼š{frame_height}ï¼Œå¸§ç‡ï¼š{fps}ï¼Œæ€»å¸§æ•°ï¼š{video_frames}")
            count = 0

            if is_capOpened:
                # åˆ›å»ºåŸå§‹å›¾ç‰‡ç›®å½•
                Path(f"{frame_savePath}/{video_name}/raw").mkdir(parents=True, exist_ok=True)
                # åˆ›å»ºæ ‡è®°å›¾ç‰‡ç›®å½•
                Path(f"{frame_savePath}/{video_name}/tag").mkdir(parents=True, exist_ok=True)
                # åˆ›å»ºPASCAL VOC XMLç›®å½•
                Path(f"{frame_savePath}/{video_name}/voc_xml").mkdir(parents=True, exist_ok=True)
                # åˆ›å»ºMS COCO JSONç›®å½•
                Path(f"{frame_savePath}/{video_name}/coco_json").mkdir(parents=True, exist_ok=True)
                # åˆ›å»ºYOLO TXTç›®å½•
                Path(f"{frame_savePath}/{video_name}/yolo_txt").mkdir(parents=True, exist_ok=True)

                vid_writer = cv2.VideoWriter(f"{frame_savePath}/{video_name}/tag/{i}",
                                             cv2.VideoWriter_fourcc(*'mp4v'), fps,
                                             (frame_width, frame_height))

                while is_capOpened:
                    ret, frame = input_video.read()
                    if not ret:
                        # åˆ¤æ–­ç©ºå¸§
                        break
                    file_path = f'{video_path} [{count}/{video_frames}]'
                    count += 1
                    frame, face_id = face_detect(file_path, mode, frame, model, frame_id, face_id, stride, names, pt,
                                                 max_det, frame_savePath, nms_conf, nms_iou,
                                                 imgName, img_size, label_no_show, label_simple,
                                                 label_progressBar, video_name)

                    vid_writer.write(frame)
                    del frame
                    gc.collect()

                coco_json_main(names, coco_imgs_list, coco_anno_list,
                               f"{frame_savePath}/{video_name}/coco_json/face_coco.json")

                input_video.release()
                cv2.destroyAllWindows()

                frame_save_msg = f"å…±è®¡{face_id}å¼ äººè„¸å›¾ç‰‡ï¼Œä¿å­˜è‡³{frame_savePath}/{video_name}/raw"
                frametag_save_msg = f"å…±è®¡{face_id}å¼ äººè„¸æ ‡è®°å›¾ç‰‡ï¼Œä¿å­˜è‡³{frame_savePath}/{video_name}/tag"
                xml_save_msg = f"å…±è®¡{face_id}ä¸ªäººè„¸xmlæ–‡ä»¶ï¼Œä¿å­˜è‡³{frame_savePath}/{video_name}/voc_xml"
                json_save_msg = f"å…±è®¡1ä¸ªäººè„¸jsonæ–‡ä»¶ï¼Œä¿å­˜è‡³{frame_savePath}/{video_name}/coco_json"
                txt_save_msg = f"å…±è®¡{face_id}ä¸ªäººè„¸txtæ–‡ä»¶ï¼Œä¿å­˜è‡³{frame_savePath}/{video_name}/yolo_txt"
                rich_log(f"{frame_save_msg}\n{frametag_save_msg}\n{xml_save_msg}\n{json_save_msg}\n{txt_save_msg}\n")

                # rich table
                table = Table(title=f"{FACELABELING_VERISON} ä¿å­˜ä¿¡æ¯", show_header=True, header_style="bold #FF6363")
                table.add_column("å±æ€§", justify="right", style="#FFAB76")
                table.add_column("ä¸ªæ•°", justify="center", style="#FFFDA2")
                table.add_column("ä¿å­˜è·¯å¾„", justify="left", style="#BAFFB4", no_wrap=True)

                table.add_row("äººè„¸å›¾ç‰‡", f"{face_id}", f"{frame_savePath}/{video_name}/raw")
                table.add_row("äººè„¸æ ‡è®°å›¾ç‰‡", f"{face_id}", f"{frame_savePath}/{video_name}/tag")
                table.add_row("äººè„¸XMLæ–‡ä»¶", f"{face_id}", f"{frame_savePath}/{video_name}/voc_xml")
                table.add_row("äººè„¸JSONæ–‡ä»¶", "1", f"{frame_savePath}/{video_name}/coco_json")
                table.add_row("äººè„¸TXTæ–‡ä»¶", f"{face_id}", f"{frame_savePath}/{video_name}/yolo_txt")

                console.print(table)

                face_id = 0
                vid_writer.release()
                input_video.release()

            else:
                print("è¿æ¥è§†é¢‘å¤±è´¥ï¼ç¨‹åºé€€å‡ºï¼")
                sys.exit()

    else:
        print("æ¨¡å¼é”™è¯¯ï¼Œç¨‹åºé€€å‡ºï¼")
        sys.exit()

    # ------------------ç¨‹åºç»“æŸ------------------
    console.rule(f"ğŸ”¥ {FACELABELING_VERISON} ç¨‹åºç»“æŸï¼")

    e_time = time.time()  # ç»ˆæ­¢æ—¶é—´
    total_time = e_time - s_time  # ç¨‹åºç”¨æ—¶

    # æ ¼å¼åŒ–æ—¶é—´æ ¼å¼ï¼Œä¾¿äºè§‚å¯Ÿ
    outTimeMsg = f"ç”¨æ—¶ï¼š{time_format(total_time)}"
    print(outTimeMsg)  # æ‰“å°ç”¨æ—¶
    rich_log(f"{outTimeMsg}\n")  # è®°å½•ç”¨æ—¶

    if mode in ["webcam", "img"]:
        frame_save_msg = f"å…±è®¡{face_id}å¼ äººè„¸å›¾ç‰‡ï¼Œä¿å­˜è‡³{frame_savePath}/raw"
        frametag_save_msg = f"å…±è®¡{face_id}å¼ äººè„¸æ ‡è®°å›¾ç‰‡ï¼Œä¿å­˜è‡³{frame_savePath}/tag"
        xml_save_msg = f"å…±è®¡{face_id}ä¸ªäººè„¸xmlæ–‡ä»¶ï¼Œä¿å­˜è‡³{frame_savePath}/voc_xml"
        json_save_msg = f"å…±è®¡1ä¸ªäººè„¸jsonæ–‡ä»¶ï¼Œä¿å­˜è‡³{frame_savePath}/coco_json"
        txt_save_msg = f"å…±è®¡{face_id}ä¸ªäººè„¸txtæ–‡ä»¶ï¼Œä¿å­˜è‡³{frame_savePath}/yolo_txt"

        rich_log(f"{frame_save_msg}\n{frametag_save_msg}\n{xml_save_msg}\n{json_save_msg}\n{txt_save_msg}\n")

        table = Table(title=f"{FACELABELING_VERISON} ä¿å­˜ä¿¡æ¯", show_header=True, header_style="bold #FF6363")
        table.add_column("å±æ€§", justify="right", style="#FFAB76")
        table.add_column("ä¸ªæ•°", justify="center", style="#FFFDA2")
        table.add_column("ä¿å­˜è·¯å¾„", justify="left", style="#BAFFB4", no_wrap=True)

        table.add_row("äººè„¸å›¾ç‰‡", f"{face_id}", f"{frame_savePath}/raw")
        table.add_row("äººè„¸æ ‡è®°å›¾ç‰‡", f"{face_id}", f"{frame_savePath}/tag")
        table.add_row("äººè„¸XMLæ–‡ä»¶", f"{face_id}", f"{frame_savePath}/voc_xml")
        table.add_row("äººè„¸JSONæ–‡ä»¶", "1", f"{frame_savePath}/coco_json")
        table.add_row("äººè„¸TXTæ–‡ä»¶", f"{face_id}", f"{frame_savePath}/yolo_txt")

        console.print(table)


def main(args):
    face_label(**vars(args))


if __name__ == "__main__":
    args = parse_args()
    main(args)
